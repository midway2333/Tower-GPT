import os
import json
import random
from pathlib import Path
from typing import Iterator, List
import tempfile

def streaming_shuffle_jsonl(
    input_dir: str,
    output_file: str,
    buffer_size: int = 100_000,
    seed: int = 42
) -> None:
    """
    æµå¼åˆå¹¶å¹¶æ‰“ä¹±æ–‡ä»¶å¤¹å†…æ‰€æœ‰ .jsonl æ–‡ä»¶ï¼Œå†…å­˜å ç”¨æ’å®šã€‚
    
    åŸç†ï¼šä½¿ç”¨ reservoir sampling çš„æ€æƒ³ï¼Œä½†æ›´ç®€å•â€”â€”
          é€è¡Œè¯»å–æ‰€æœ‰æ–‡ä»¶ï¼Œå°†è¡Œç¼“å­˜åˆ° bufferï¼Œbuffer æ»¡æ—¶æ‰“ä¹±å¹¶å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œ
          æœ€åå†åˆå¹¶æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶å¹¶äºŒæ¬¡æ‰“ä¹±ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰ã€‚
    
    å‚æ•°:
        input_dir (str): è¾“å…¥æ–‡ä»¶å¤¹
        output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        buffer_size (int): å†…å­˜ç¼“å†²åŒºå¤§å°ï¼ˆè¡Œæ•°ï¼‰ï¼Œé»˜è®¤ 10 ä¸‡è¡Œ â‰ˆ å‡ ç™¾ MB
        seed (int): éšæœºç§å­
    """
    input_path = Path(input_dir)
    if not input_path.is_dir():
        raise ValueError(f"è¾“å…¥è·¯å¾„ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶å¤¹: {input_dir}")

    jsonl_files = sorted([f for f in input_path.iterdir() if f.is_file() and f.suffix.lower() == '.jsonl'])
    if not jsonl_files:
        print(f"âš ï¸  æœªæ‰¾åˆ° .jsonl æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(jsonl_files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æµå¼æ‰“ä¹±...")

    # ç¬¬ä¸€é˜¶æ®µï¼šåˆ†å—æ‰“ä¹±ï¼Œå†™å…¥ä¸´æ—¶æ–‡ä»¶
    temp_files: List[Path] = []
    buffer: List[str] = []
    random.seed(seed)

    def flush_buffer():
        if buffer:
            random.shuffle(buffer)
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.jsonl', encoding='utf-8') as tmp:
                tmp.write("\n".join(buffer) + "\n")
                temp_files.append(Path(tmp.name))
            buffer.clear()

    # è¯»å–æ‰€æœ‰è¡Œï¼Œåˆ†å—æ‰“ä¹±
    line_count = 0
    for file in jsonl_files:
        with open(file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    json.loads(line)  # éªŒè¯ JSON åˆæ³•æ€§
                    buffer.append(line)
                    line_count += 1
                except json.JSONDecodeError:
                    continue

                if len(buffer) >= buffer_size:
                    flush_buffer()

    # åˆ·æ–°å‰©ä½™ buffer
    flush_buffer()

    if not temp_files:
        print("âŒ æ— æœ‰æ•ˆæ•°æ®")
        return

    print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼šå…± {line_count} è¡Œï¼Œç”Ÿæˆ {len(temp_files)} ä¸ªä¸´æ—¶æ–‡ä»¶")

    # ç¬¬äºŒé˜¶æ®µï¼šåˆå¹¶ä¸´æ—¶æ–‡ä»¶ + å…¨å±€äºŒæ¬¡æ‰“ä¹±ï¼ˆä½¿ç”¨ç›¸åŒ buffer ç­–ç•¥ï¼‰
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # æ‰“å¼€æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ä½œä¸ºè¿­ä»£å™¨
    file_iters: List[Iterator[str]] = []
    for tmp_file in temp_files:
        f = open(tmp_file, 'r', encoding='utf-8')
        file_iters.append(iter(f.readline, ''))

    # ä½¿ç”¨å¤šè·¯å½’å¹¶ + buffer æ‰“ä¹±ï¼ˆç®€åŒ–ç‰ˆï¼šç›´æ¥è¯»æ‰€æœ‰å†åˆ† bufferï¼‰
    # æ›´é«˜æ•ˆåšæ³•æ˜¯ç”¨ heapqï¼Œä½†ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å†åšä¸€æ¬¡ buffer shuffle
    final_buffer: List[str] = []

    def write_final_buffer():
        if final_buffer:
            random.shuffle(final_buffer)
            with open(output_path, 'a', encoding='utf-8') as out_f:
                out_f.write("".join(final_buffer))
            final_buffer.clear()

    # é€è¡Œä»ä¸´æ—¶æ–‡ä»¶è¯»å–ï¼ˆé¡ºåºè¯»ï¼Œä½†å†…å®¹å·²å±€éƒ¨æ‰“ä¹±ï¼‰
    for tmp_file in temp_files:
        with open(tmp_file, 'r', encoding='utf-8') as f:
            for line in f:
                final_buffer.append(line)
                if len(final_buffer) >= buffer_size:
                    write_final_buffer()

    write_final_buffer()

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for tmp in temp_files:
        tmp.unlink()

    print(f"ğŸ‰ æµå¼æ‰“ä¹±å®Œæˆï¼è¾“å‡º: {output_file}")
    print(f"ğŸ“Š æ€»è¡Œæ•°: {line_count} (ä¼°ç®—)")


# ============ ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    streaming_shuffle_jsonl(
        input_dir="data",
        output_file="data2/train.jsonl",
        buffer_size=1000000,  # æ ¹æ®å†…å­˜è°ƒæ•´ï¼Œ20ä¸‡è¡Œ â‰ˆ 500MB~1GB
        seed=42
    )